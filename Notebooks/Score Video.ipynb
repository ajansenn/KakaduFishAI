{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xlsxwriter\n",
    "!{sys.executable} -m pip install azure-storage-blob==12.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2, io, json, logging, os, sys, tempfile,uuid\n",
    "import numpy as np\n",
    "import xlsxwriter \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateEntry, Region\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from matplotlib.patches import Rectangle\n",
    "from datetime import datetime, timedelta\n",
    "from azure.storage.blob import ResourceTypes, AccountSasPermissions, AccessPolicy, ContainerSasPermissions,generate_container_sas,BlobServiceClient, BlobClient, ContainerClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint for the personal training\n",
    "endpoint = \"https://<enter name here>.cognitiveservices.azure.com/\"\n",
    "\n",
    "# Replace with a valid key\n",
    "prediction_key = \"Â¯\\_(ãƒ„)_/Â¯\"\n",
    "projectID = \"ðŸ™ƒ\"\n",
    "\n",
    "# Replace with a valid iteration \n",
    "iteration = \"Iteration9\"\n",
    "\n",
    "# Replace with a valid file path on your desktop with videos\n",
    "path = \"C:\\\\2019\\Channel Billabong\\\\Sandy Billabong\\\\Transect 4\\\\Location 10\"\n",
    "# Storage connection string format \"DefaultEndpointsProtocol=https;AccountName=audiostores2tg********\"\n",
    "connect_str = \"DefaultEndpointsProtocol=htt*****\"\n",
    "\n",
    "# dictionary list for thresholding prediction values from Custom Vision\n",
    "thresholding_values = {\n",
    "    \"Ambassis agrammus\":50 ,\n",
    "    \"Ambassis macleayi\":50 ,\n",
    "    \"Amniataba percoides\":50 ,\n",
    "    \"Craterocephalus sturcusmuscarum\":50,\n",
    "    \"Denariusa bandata\":50,\n",
    "    \"Glossamia aprion\":50,\n",
    "    \"Glossogobius spp.\": 50,\n",
    "    \"Hephaestus fuliginosus\": 50,\n",
    "    \"Lates calcarifer\":50,\n",
    "    \"Leiopotherapon unicolor\": 50,\n",
    "    \"Liza ordensis\": 50,\n",
    "    \"Megalops cyprinoides\": 50,\n",
    "    \"Melanotaenia nigrans\":50 ,\n",
    "    \"Melanotaenia splendida inornata\":50,\n",
    "    \"Mogurnda mogurnda\": 50,\n",
    "    \"Nemetalosa erebi\": 50,\n",
    "    \"Neoarius spp.\":50,\n",
    "    \"Neosilurus spp.\":50,\n",
    "    \"Oxyeleotris spp.\": 50,\n",
    "    \"Other\":50,\n",
    "    \"Scleropages jardinii\":50,\n",
    "    \"Strongylura krefftii\":50,\n",
    "    \"Sycomistes butleri\":50,\n",
    "    \"Toxotes chatareus\":50 \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_info(file_path):\n",
    "\n",
    "    file_info = {}\n",
    "\n",
    "    parts = file_path.split(os.sep)\n",
    "\n",
    "    file_info['video_name'] = os.path.splitext(parts[-1])[0]\n",
    "    file_info['location_name'] = parts[-2]\n",
    "    file_info['transect_name'] = parts[-3]\n",
    "    file_info['site_name'] = parts[-4]\n",
    "    file_info['billabong_type'] = parts[-5]\n",
    "    file_info['year'] = parts[-6]\n",
    "\n",
    "    return file_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(results, np_image, frame_count, fps, min_probability, debug=False):\n",
    "    print(results.id)\n",
    "    \n",
    "    for prediction in results.predictions:\n",
    "        if prediction.tag_name not in thresholding_values:\n",
    "            print (\"WARNING: The Species name is not in threshold dictionary, probability is set to default\")\n",
    "            probability = min_probability\n",
    "        else:\n",
    "            probability = thresholding_values[prediction.tag_name]\n",
    "\n",
    "        if (prediction.probability * 100) > probability:\n",
    "            x1 = int(prediction.bounding_box.left * np_image.shape[1])\n",
    "            y1 = int(prediction.bounding_box.top * np_image.shape[0])\n",
    "            x2 = x1 + int(prediction.bounding_box.width * np_image.shape[1])\n",
    "            y2 = y1 + int(prediction.bounding_box.height * np_image.shape[0])\n",
    "        \n",
    "            cv2.rectangle(np_image, (x1, y1), (x2, y2), (255,0,0), 2)\n",
    "    \n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_vision_predictor(file_path, prediction_key, endpoint, projectID,thresholding_values, iteration, predictions_per_sec=1, min_probability=50, debug=False):\n",
    "    # Getting parameters from the path\n",
    "    predictor = CustomVisionPredictionClient(prediction_key, endpoint=endpoint)\n",
    "    file_info = get_file_info(file_path)\n",
    "\n",
    "    # Split video into frames\n",
    "    video_dir = os.path.join(file_info['year'], file_info['billabong_type'], file_info['site_name'], file_info['transect_name'],file_info['location_name']).replace(os.sep, '-').replace(' ', '-')\n",
    "            \n",
    "    starting_time = 0 # Seconds...\n",
    "\n",
    "    video_capture = cv2.VideoCapture(file_path)\n",
    "\n",
    "    num_of_frames = video_capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Frames per second: {fps}\")\n",
    "        print(f\"Total frame count: {video_capture.get(cv2.CAP_PROP_FRAME_COUNT)}\")\n",
    "\n",
    "    frame_count = int(starting_time * fps)\n",
    "\n",
    "    video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
    "\n",
    "    error_frame_count = 0\n",
    "    \n",
    "    writer = None\n",
    "\n",
    "    # Analyse video frames and ran custom vision \n",
    "    while video_capture.isOpened():\n",
    "        success, np_image = video_capture.read()\n",
    "\n",
    "        if (frame_count % (fps//predictions_per_sec)) == 0:\n",
    "            if success is False:\n",
    "                print(f'Could not process frame: {frame_count} of {num_of_frames}')\n",
    "                error_frame_count += 1\n",
    "                frame_count += 1\n",
    "\n",
    "                if frame_count == num_of_frames:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            frame_name = '{0}_Frame-{1}.jpg'.format(video_dir, frame_count)\n",
    "\n",
    "            np_image = cv2.cvtColor(np_image, cv2.COLOR_BGR2RGB)\n",
    "            buffer = io.BytesIO()\n",
    "            Image.fromarray(np_image).save(buffer, format='JPEG')\n",
    "            results = predictor.detect_image(projectID, iteration, buffer.getvalue())\n",
    "            \n",
    "            if writer is None:\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "                writer = cv2.VideoWriter('{0}-Scored.MP4'.format(video_dir), fourcc, video_capture.get(cv2.CAP_PROP_FPS),(np_image.shape[1], np_image.shape[0]), True)\n",
    "            \n",
    "            np_image = draw_bounding_boxes(results,np_image,frame_count,fps,min_probability,debug)\n",
    "            \n",
    "            writer.write(np_image)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        if frame_count == num_of_frames:\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    \n",
    "    writer.release()\n",
    "\n",
    "    print(f\"Total video frames:{num_of_frames}\")\n",
    "    print(f\"Total frames to process: {num_of_frames/fps}\")\n",
    "    print(f\"Total processed frames that errored: {error_frame_count}\")\n",
    "    # print(f'Total number of unprocessed frames: {error_frame_count} of {num_of_frames/fps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = os.listdir(path)\n",
    "\n",
    "for f in files:\n",
    "    if os.path.splitext(f)[1] == '.mp4':\n",
    "        file_path = path + '\\\\' + f\n",
    "\n",
    "        custom_vision_predictor(file_path, prediction_key, endpoint, projectID, thresholding_values, iteration, predictions_per_sec=1, min_probability=15, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.5 ('KakaduFishAI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "bb5dd9730ce0bf30ff57e681a8b71c7c978f58acbf7485b351796755d3f9f2ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
